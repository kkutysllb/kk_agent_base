{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据检索\n",
    "用户输入只是问题，答案需要从已知的数据库或者文档中获取。因此，我们需要使用检索器获取上下文，并通过“question”键下的用户输入。\n",
    "\n",
    "### RAG\n",
    "检索增强生成（Retrieval-augmented Generation，RAG），是当下最热门的大模型前沿技术之一。如果将“微调（finetune）”理解成大模型内化吸收知识的过程，那么RAG就相当于给大模型装上了“知识外挂”，基础大模型不用再训练即可随时调用特定领域知识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f5/wwjgctq529v381m5rw2lrfr00000gn/T/ipykernel_99416/3003229924.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=embeddings_path)\n",
      "/Users/libing/miniconda3/envs/kk_agent/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_path = \"/Users/libing/kk_LLMs/bge-large-zh-v1.5\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embeddings_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x16c4271f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = FAISS.from_texts([\"小明在华为工作\", \"熊喜欢吃蜂蜜\"], \n",
    "                               embeddings)\n",
    "\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='小明在华为工作'),\n",
       " Document(metadata={}, page_content='熊喜欢吃蜂蜜')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用向量数据库生成检索器\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 使用检索器获取上下文\n",
    "context = retriever.invoke(\"小明喜欢吃什么\")\n",
    "\n",
    "context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接本地大模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "api_key = \"xxx\"\n",
    "base_url = \"http://localhost:1234/v1\"\n",
    "\n",
    "chat = ChatOpenAI(api_key=api_key, base_url=base_url, temperature=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "你是一个调查员，请根据以下信息回答问题：\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据提供的信息，我们无法得知小明的具体饮食偏好或他是否喜欢吃某种特定的食物。给出的信息中只提到“小明在华为工作”，并没有关于他的饮食习惯的描述。因此，对于“小明喜欢吃什么”的问题，目前没有足够的信息来回答。如果需要了解小明的喜好，可能需要更多的相关信息或者直接询问小明本人。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retriever = RunnableParallel(\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = setup_and_retriever | prompt | chat | output_parser\n",
    "\n",
    "chain.invoke(\"小明喜欢吃什么\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'小明在华为工作。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#完整链式\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chat\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"小明在哪里工作？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好，根据提供的信息，调查员可以告诉您，熊喜欢吃蜂蜜。"
     ]
    }
   ],
   "source": [
    "# 一个完整的示例\n",
    "from operator import itemgetter\n",
    "\n",
    "template = \"\"\"\n",
    "你是一个调查员，请根据以下信息回答问题：\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "回答问题时请礼貌称呼: {name}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"name\": itemgetter(\"name\")\n",
    "    }\n",
    "    | prompt\n",
    "    | chat\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "for m in chain.stream({\"question\": \"熊喜欢吃什么\", \"name\": \"调查员\"}):\n",
    "    print(m, end=\"\", flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
